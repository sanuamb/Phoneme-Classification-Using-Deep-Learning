# Phoneme Classification Using Deep Learning

1. data_preprocess.m contains preprocessing of audios and their phoneme labels. First section of this file is to create mel filterbanks for MFCC feature extraction. We have referred to the matlab built-in function definitions of how to create Mel filterbanks from their audio processing toolkit. Run the first section.

2. The second section of data_preprocess.m is to read wav files and their respective phonemes, also extracting MFCC features from them. We have used GNU public licensed readsph function to read .phn file to extract label of respective audio files. Run this section either providing dataset value as test or train.

3. generate_labels.m uses the mat files generated by the data_preprocess.m to fold the 61 phonemes into respective classes.

4. Models.py has 16 models with first 4 models trained on one layer DNN, 5-8 models are trained on two layer DNN, 9-12 models are trained on three layer DNN and 13-16 models are trained on LSTM, All these models are trained on all phonemes and 3 different groupings of labels
